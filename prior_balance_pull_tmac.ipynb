{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pipenv install pyodbc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import base64\n",
    "import pyodbc\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Connection\n",
    "password = config.password\n",
    "# Connecting to SQL Server\n",
    "client_code = '544'\n",
    "database = 'SS'\n",
    "base_dir = r\"C:\\Users\\jesse.henson\\StaffScapes\\StaffScapes - Documents\\IT\\Isolved Import\\prior_balance\\imports\"\n",
    "conn = pyodbc.connect('Driver={SQL Server Native Client 10.0};'\n",
    "                      'Server=staffc-darwin\\darwin12;'\n",
    "                      f'Database={database};'\n",
    "                      'UID=username;'\n",
    "                      'PWD=' + password + ';')\n",
    "if not os.path.isdir(f'{base_dir}/{client_code}'):\n",
    "    os.mkdir(f'{base_dir}/{client_code}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paycode Data\n",
    "# Read it \n",
    "sql_str = f\"Select EMPLOYID as [Key], DEPRTMNT as LaborValue2, CHEKNMBR as CheckNumber, AUCTRLCD as ControlNumber,  CHEKDATE as CheckDate,  UNTSTOPY as hours, PYRLRTYP as PayType, PAYROLCD as PayCode, uprtrxam as dollars, TRXBEGDT as PeriodBeginDate, TRXENDDT as PeriodEndDate from upr30300 where employid between '{'F1' if database == 'AHR' else '01'}{client_code}0001' and '{'F1' if database == 'AHR' else '01'}{client_code}9999'\"\n",
    "paycode_data = pd.read_sql_query(sql_str,conn,parse_dates=['PeriodBeginDate','PeriodEndDate','CheckDate'])\n",
    "paycode_data['PayPrefix'] = paycode_data['PayType'].map({1:'E_', 4:'T_', 2:'D_', 3:'M_'})\n",
    "paycode_data['PayCode'] = paycode_data['PayCode'].apply(lambda x:x.strip())\n",
    "paycode_data['PayCode'].replace(to_replace='BONUS~',value='BONUS',inplace=True)\n",
    "paycode_data['PayCode'] = paycode_data['PayPrefix'] + paycode_data['PayCode']\n",
    "paycode_data['PayCode'] = paycode_data['PayCode'].fillna('Missing')\n",
    "paycode_data['PayCodeHour'] = paycode_data['PayCode'].apply(lambda x: x + '_Hours' if x[0] == 'E' else x)\n",
    "paycode_data['PayCode'] = paycode_data['PayCode'].apply(lambda x: x + '_Dollars' if x[0] in ['M','E'] else x)\n",
    "# paycode_data['PayCode'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ben_ded_bp_dict = {}\n",
    "\n",
    "def closest_word(written_word, target_word):\n",
    "    score = 0\n",
    "    number_of_matches = 0\n",
    "    temp_written = written_word\n",
    "    temp_target = target_word\n",
    "    for written_char in written_word:\n",
    "        if written_char in target_word:\n",
    "            target_word = target_word.replace(written_char, '',1)\n",
    "            written_word = written_word.replace(written_char, '',1)\n",
    "            number_of_matches += 1\n",
    "            score += 100\n",
    "        for char_left in written_word: \n",
    "            if char_left in temp_target:\n",
    "                score += 50\n",
    "            else: \n",
    "                score -= 10\n",
    "        for char_left in target_word:\n",
    "            if char_left in temp_written:\n",
    "                score += 50\n",
    "            else:\n",
    "                score -= 10\n",
    "    return (score)\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ded_score_keeper = []\n",
    "\n",
    "\n",
    "\n",
    "bp_ded_codes = paycode_data[paycode_data['PayCode'].str.count('D_BP') > 0].PayCode\n",
    "bp_ded_arr = bp_ded_codes.unique()\n",
    "\n",
    "ded_codes = paycode_data[paycode_data['PayCode'].str.count('^D_((?!BP).)*$') > 0].PayCode\n",
    "ded_arr = ded_codes.unique()\n",
    "ded_arr\n",
    "\n",
    "for bp_ded in bp_ded_arr:\n",
    "    ded_score_keeper = []\n",
    "    for ded in ded_arr:\n",
    "        temp_score = closest_word(bp_ded.strip()[bp_ded.index('-')+1:], ded.strip()[ded.index('_')+1:])\n",
    "        ded_score_keeper.append((temp_score, bp_ded, ded))\n",
    "    ben_ded_bp_dict[max(ded_score_keeper)[1]] = max(ded_score_keeper)[2]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ben_score_keeper = []\n",
    "\n",
    "\n",
    "\n",
    "bp_ben_codes = paycode_data[paycode_data['PayCode'].str.count('M_BP') > 0].PayCode\n",
    "bp_ben_arr = bp_ben_codes.unique()\n",
    "\n",
    "ben_codes = paycode_data[paycode_data['PayCode'].str.count('M_((?!BP).)*$') > 0].PayCode\n",
    "ben_arr = ben_codes.unique()\n",
    "ben_arr\n",
    "\n",
    "for bp_ben in bp_ben_arr:\n",
    "    ben_score_keeper = []\n",
    "    for ben in ben_arr:\n",
    "        temp_score = closest_word(bp_ben.strip()[bp_ben.index('-')+1:bp_ben.index('Dollars')], ben.strip()[ben.index('_')+1:ben.index('Dollars')])\n",
    "        ben_score_keeper.append((temp_score, bp_ben, ben))\n",
    "    ben_ded_bp_dict[max(ben_score_keeper)[1]] = max(ben_score_keeper)[2]\n",
    "\n",
    "# print(bp_ben_arr)\n",
    "# print(ben_arr)\n",
    "print(ben_ded_bp_dict)\n",
    "# ben_ded_bp_dict['M_BP-VIS_Dollars'] = 'M_VIS_Dollars'\n",
    "print(ben_ded_bp_dict)\n",
    "# ben_ded_bp_dict['D_BP-MD1'] = 'D_UHC-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paycode_pivot_dollars = paycode_data.copy()\n",
    "paycode_pivot_dollars = paycode_pivot_dollars.pivot_table(index=['Key','ControlNumber'], columns='PayCode', fill_value=0, values=['dollars'], aggfunc=np.sum)\n",
    "paycode_pivot_dollars.columns = paycode_pivot_dollars.columns.droplevel(level=0)\n",
    "paycode_pivot_dollars.reset_index(inplace=True)\n",
    "# paycode_pivot_dollars[paycode_pivot_dollars['Key'] == '015400051      ']['E_HOURLY_Dollars']\n",
    "# paycode_pivot_dollars.filter(like='015400051', axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paycode_pivot_hours = paycode_data.copy()\n",
    "paycode_pivot_hours = paycode_pivot_hours.pivot_table(index=['Key','ControlNumber'], columns='PayCodeHour', fill_value=0, values=['hours'], aggfunc=np.sum)\n",
    "paycode_pivot_hours.columns = paycode_pivot_hours.columns.droplevel(level=0)\n",
    "paycode_pivot_hours.reset_index(inplace=True)\n",
    "columns = [col for col in paycode_pivot_hours.columns if 'Hours' not in col and col != 'Key' and col != 'ControlNumber']\n",
    "paycode_pivot_hours = paycode_pivot_hours[paycode_pivot_hours.columns.drop(columns)]\n",
    "# paycode_pivot_hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paycode_pivot = paycode_pivot_hours.merge(paycode_pivot_dollars, on=['Key','ControlNumber'])\n",
    "# paycode_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create non-pivoted table\n",
    "check_meta_data = paycode_data.loc[:,['Key','CheckNumber','CheckDate','LaborValue2','PeriodBeginDate','PeriodEndDate', 'ControlNumber']]\n",
    "check_meta_data = check_meta_data.drop_duplicates(subset=['Key','ControlNumber'])\n",
    "# check_meta_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data\n",
    "sql_str = f\"Select EMPLOYID as [Key],AUCTRLCD as ControlNumber, FDWDGPRN + FDTXTIPS as T_FEDWT, FICAMWPR + FICMTPTX as T_MEDEE, FCASWPR + FICSTPTX as T_SOCSECEE from upr30100 where employid between '{'F1' if database == 'AHR' else '01'}{client_code}0001' and '{'F1' if database == 'AHR' else '01'}{client_code}9999'\"\n",
    "check_data = pd.read_sql_query(sql_str,conn)\n",
    "print(check_data.columns)\n",
    "# check_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUTA SUTA Data\n",
    "sql_str = f\"select employid as [Key], AUCTRLCD as ControlNumber, PYRLRTYP as payType, TW_FUTA_Liability, TXBLWAGS as #TaxableWage from tw80507 where employid between '{'F1' if database == 'AHR' else '01'}{client_code}0001' and '{'F1' if database == 'AHR' else '01'}{client_code}9999'\"\n",
    "employer_data = pd.read_sql_query(sql_str,conn)\n",
    "# Pivot data\n",
    "employer_data[['Key','ControlNumber','payType','TW_FUTA_Liability']]\n",
    "employer_data_pivot = employer_data[['Key','ControlNumber','payType','TW_FUTA_Liability']].pivot_table(index=['Key','ControlNumber'], columns='payType')\n",
    "new_columns = ['T_SUIER','# FUTA From Darwin','T_WRKCOMPER']\n",
    "employer_data_pivot.columns = new_columns\n",
    "employer_data_pivot\n",
    "\n",
    "employer_data_pivot.reset_index(inplace=True)\n",
    "# employer_data_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Creat Table for taxable wage\n",
    "taxable_wage = employer_data[['Key','ControlNumber','#TaxableWage','payType']].query('payType == 2')\n",
    "# taxable_wage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the two tables\n",
    "employer_data_final = pd.merge(left=employer_data_pivot, right=taxable_wage, on=['Key','ControlNumber'])\n",
    "\n",
    "# Create FUTA liability actual\n",
    "employer_data_final['T_FUTAER'] = employer_data_final['#TaxableWage'] * .006\n",
    "\n",
    "\n",
    "# employer_data_final\n",
    "# employer_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge all three "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_history_data = pd.merge(left=employer_data_final,right=check_data,on=['Key','ControlNumber'])\n",
    "prior_history_data = pd.merge(left=prior_history_data, right=check_meta_data, on=['Key','ControlNumber'])\n",
    "prior_history_data = pd.merge(left=prior_history_data, right=paycode_pivot, on=['Key','ControlNumber'])\n",
    "prior_history_data.rename(columns = {\"ControlNumber\": \"#ControlNumber\"}, inplace=True)\n",
    "prior_history_data['Key'] = prior_history_data['Key'].str[2:]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "prior_history_data['E_REG_Hours'] = prior_history_data['E_SALARY_Hours'] + prior_history_data['E_HOURLY_Hours']\n",
    "prior_history_data['E_REG_Dollars'] = prior_history_data['E_SALARY_Dollars'] + prior_history_data['E_HOURLY_Dollars']\n",
    "prior_history_data = prior_history_data.drop(columns=['E_SALARY_Hours','E_SALARY_Dollars','E_HOURLY_Hours','E_HOURLY_Dollars'])\n",
    "\n",
    "# prior_history_data.rename(columns={'E_HOURLY_Hours':'E_REG_Hours','E_HOURLY_Dollars':'E_REG_Dollars'},inplace=True)\n",
    "# prior_history_data.rename(columns={'E_SALARY_Hours':'E_REG_Hours','E_SALARY_Dollars':'E_REG_Dollars'}, inplace=True)\n",
    "\n",
    "\n",
    "try: \n",
    "    prior_history_data.rename(columns={prior_history_data.filter(regex='D_TAX.*').columns[0]: 'T_HEAD',\n",
    "                                      prior_history_data.filter(regex='M_TAX.*').columns[0]: 'T_LOCMISCER'}, inplace = True)\n",
    "except:\n",
    "    print('no head tax')\n",
    "prior_history_data.rename(columns={'T_CO':'T_STATEWT', 'payType':'#payType','D_CHILD1':'G_Child Support_1','G_GRN1':'G_Child Support_1'}, inplace=True)\n",
    "\n",
    "print(ben_ded_bp_dict)\n",
    "\n",
    "\n",
    "for bp_code, reg_code in ben_ded_bp_dict.items():\n",
    "    prior_history_data['#' + reg_code] = prior_history_data[reg_code] + prior_history_data[bp_code]\n",
    "    prior_history_data[reg_code] = prior_history_data['#' +reg_code]  \n",
    "\n",
    "    \n",
    "columns = [key for key, value in ben_ded_bp_dict.items()]\n",
    "          \n",
    "prior_history_data = prior_history_data.drop(columns=columns)\n",
    "prior_history_data = prior_history_data.loc[:, (prior_history_data != 0).any(axis=0)]\n",
    "prior_history_data = prior_history_data.round(2)\n",
    "prior_history_data = prior_history_data[prior_history_data['CheckDate']>'01/01/2021']\n",
    "# prior_history_data['E_PTO_Dollars'] = prior_history_data['E_PTO_Dollars'] + prior_history_data['E_PTO-M_Dollars']\n",
    "# prior_history_data['E_PTO_Hours'] = prior_history_data['E_PTO_Hours'] + prior_history_data['E_PTO-M_Hours']\n",
    "# prior_history_data.rename(columns={'E_PTO-M_Hours': '#E_PTO-M_Hours','E_PTO-M_Dollars':'#E_PTO-M_Dollars'}, inplace=True)\n",
    "prior_history_data.drop_duplicates(subset=['Key','#ControlNumber'], inplace=True)\n",
    "prior_history_data.to_csv(f\"{base_dir}/{client_code}/{client_code}_prior_balance.csv\")\n",
    "prior_history_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "TODO\n",
    "Combine salary and hourly into Reg - add together the two columns and rename to E_REG_Dollars/hours\n",
    "get rid of additional D/T/m columns\n",
    "Delete Bonus/Comm/Flat column Hours\n",
    "Set M in front when Memo \n",
    "Set T_<<<STATE>>> to T_STATEWT\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flag = False\n",
    "\n",
    "for column in prior_history_data.columns:\n",
    "    if 'BP' in column:\n",
    "        flag = True\n",
    "        \n",
    "flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}